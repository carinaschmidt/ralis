{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "net_path = \"/mnt/qb/baumgartner/cschmidt77_data/ckpt_seg_new/camvid_pretrained_dt/best_jaccard_val.pth\"\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "net_dict = torch.load(net_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "net_dict"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "#from models import fpn\n",
    "import fpn\n",
    "from fpn import FPN50"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "n_cl = 4"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "net = FPN50(11)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "net.load_state_dict(net_dict)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "net"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "net.classifier = torch.nn.Conv2d(in_channels=512, out_channels=4, kernel_size=3, stride=1, padding=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "net"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "FPN(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): ModuleList(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): ModuleList(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): ModuleList(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): ModuleList(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): ModuleList(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): ModuleList(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): ModuleList(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): ModuleList(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (toplayer): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (smooth0): Sequential(\n",
       "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (smooth1): Sequential(\n",
       "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (smooth2): Sequential(\n",
       "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (smooth3): Sequential(\n",
       "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (latlayer1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (latlayer2): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (latlayer3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (latup0): Upsample(\n",
       "    (up): Upsample(scale_factor=8.0, mode=bilinear)\n",
       "    (up_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (latup1): Upsample(\n",
       "    (up): Upsample(scale_factor=4.0, mode=bilinear)\n",
       "    (up_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (latup2): Upsample(\n",
       "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "    (up_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (classifier): Conv2d(512, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (final_up): Upsample(scale_factor=4.0, mode=bilinear)\n",
       "  (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "random_tensor = torch.randn(64, 3, 7, 7)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "net(random_tensor)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/carina/.local/lib/python3.8/site-packages/torch/nn/functional.py:3328: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[[[ 5.1856e-02,  5.0169e-02,  4.8482e-02,  ...,  4.3420e-02,\n",
       "             4.1733e-02,  4.0046e-02],\n",
       "           [ 5.0688e-02,  4.8304e-02,  4.5919e-02,  ...,  3.8765e-02,\n",
       "             3.6380e-02,  3.3995e-02],\n",
       "           [ 4.9521e-02,  4.6438e-02,  4.3356e-02,  ...,  3.4109e-02,\n",
       "             3.1027e-02,  2.7945e-02],\n",
       "           ...,\n",
       "           [ 4.6017e-02,  4.0842e-02,  3.5668e-02,  ...,  2.0143e-02,\n",
       "             1.4968e-02,  9.7927e-03],\n",
       "           [ 4.4850e-02,  3.8977e-02,  3.3105e-02,  ...,  1.5487e-02,\n",
       "             9.6147e-03,  3.7422e-03],\n",
       "           [ 4.3682e-02,  3.7112e-02,  3.0542e-02,  ...,  1.0832e-02,\n",
       "             4.2616e-03, -2.3084e-03]],\n",
       " \n",
       "          [[ 4.2869e-02,  5.5089e-02,  6.7310e-02,  ...,  1.0397e-01,\n",
       "             1.1619e-01,  1.2841e-01],\n",
       "           [ 4.7103e-02,  5.7970e-02,  6.8836e-02,  ...,  1.0143e-01,\n",
       "             1.1230e-01,  1.2317e-01],\n",
       "           [ 5.1338e-02,  6.0850e-02,  7.0362e-02,  ...,  9.8899e-02,\n",
       "             1.0841e-01,  1.1792e-01],\n",
       "           ...,\n",
       "           [ 6.4041e-02,  6.9491e-02,  7.4941e-02,  ...,  9.1290e-02,\n",
       "             9.6740e-02,  1.0219e-01],\n",
       "           [ 6.8276e-02,  7.2372e-02,  7.6467e-02,  ...,  8.8754e-02,\n",
       "             9.2849e-02,  9.6945e-02],\n",
       "           [ 7.2511e-02,  7.5252e-02,  7.7993e-02,  ...,  8.6217e-02,\n",
       "             8.8959e-02,  9.1700e-02]],\n",
       " \n",
       "          [[ 6.1240e-03,  5.9056e-03,  5.6872e-03,  ...,  5.0318e-03,\n",
       "             4.8134e-03,  4.5950e-03],\n",
       "           [ 4.7415e-03,  5.2053e-03,  5.6691e-03,  ...,  7.0603e-03,\n",
       "             7.5241e-03,  7.9878e-03],\n",
       "           [ 3.3591e-03,  4.5050e-03,  5.6510e-03,  ...,  9.0888e-03,\n",
       "             1.0235e-02,  1.1381e-02],\n",
       "           ...,\n",
       "           [-7.8841e-04,  2.4041e-03,  5.5967e-03,  ...,  1.5174e-02,\n",
       "             1.8367e-02,  2.1559e-02],\n",
       "           [-2.1709e-03,  1.7038e-03,  5.5786e-03,  ...,  1.7203e-02,\n",
       "             2.1078e-02,  2.4952e-02],\n",
       "           [-3.5534e-03,  1.0035e-03,  5.5605e-03,  ...,  1.9231e-02,\n",
       "             2.3788e-02,  2.8345e-02]],\n",
       " \n",
       "          [[ 2.4735e-02,  2.7450e-02,  3.0165e-02,  ...,  3.8309e-02,\n",
       "             4.1024e-02,  4.3739e-02],\n",
       "           [ 2.8609e-02,  3.0917e-02,  3.3225e-02,  ...,  4.0151e-02,\n",
       "             4.2459e-02,  4.4768e-02],\n",
       "           [ 3.2482e-02,  3.4384e-02,  3.6286e-02,  ...,  4.1992e-02,\n",
       "             4.3894e-02,  4.5796e-02],\n",
       "           ...,\n",
       "           [ 4.4104e-02,  4.4787e-02,  4.5469e-02,  ...,  4.7517e-02,\n",
       "             4.8200e-02,  4.8882e-02],\n",
       "           [ 4.7978e-02,  4.8254e-02,  4.8530e-02,  ...,  4.9358e-02,\n",
       "             4.9635e-02,  4.9911e-02],\n",
       "           [ 5.1852e-02,  5.1721e-02,  5.1591e-02,  ...,  5.1200e-02,\n",
       "             5.1070e-02,  5.0939e-02]]],\n",
       " \n",
       " \n",
       "         [[[-2.2415e-02, -2.1528e-02, -2.0641e-02,  ..., -1.7978e-02,\n",
       "            -1.7091e-02, -1.6203e-02],\n",
       "           [-1.6733e-02, -1.6418e-02, -1.6103e-02,  ..., -1.5157e-02,\n",
       "            -1.4842e-02, -1.4526e-02],\n",
       "           [-1.1051e-02, -1.1308e-02, -1.1565e-02,  ..., -1.2336e-02,\n",
       "            -1.2592e-02, -1.2849e-02],\n",
       "           ...,\n",
       "           [ 5.9951e-03,  4.0217e-03,  2.0484e-03,  ..., -3.8716e-03,\n",
       "            -5.8449e-03, -7.8182e-03],\n",
       "           [ 1.1677e-02,  9.1317e-03,  6.5862e-03,  ..., -1.0502e-03,\n",
       "            -3.5957e-03, -6.1412e-03],\n",
       "           [ 1.7359e-02,  1.4242e-02,  1.1124e-02,  ...,  1.7711e-03,\n",
       "            -1.3465e-03, -4.4641e-03]],\n",
       " \n",
       "          [[ 4.8554e-02,  4.7467e-02,  4.6379e-02,  ...,  4.3117e-02,\n",
       "             4.2029e-02,  4.0942e-02],\n",
       "           [ 4.4074e-02,  4.2914e-02,  4.1755e-02,  ...,  3.8275e-02,\n",
       "             3.7115e-02,  3.5955e-02],\n",
       "           [ 3.9595e-02,  3.8362e-02,  3.7130e-02,  ...,  3.3433e-02,\n",
       "             3.2200e-02,  3.0968e-02],\n",
       "           ...,\n",
       "           [ 2.6155e-02,  2.4706e-02,  2.3256e-02,  ...,  1.8907e-02,\n",
       "             1.7457e-02,  1.6008e-02],\n",
       "           [ 2.1675e-02,  2.0153e-02,  1.8631e-02,  ...,  1.4065e-02,\n",
       "             1.2543e-02,  1.1021e-02],\n",
       "           [ 1.7196e-02,  1.5601e-02,  1.4007e-02,  ...,  9.2232e-03,\n",
       "             7.6287e-03,  6.0342e-03]],\n",
       " \n",
       "          [[-1.1732e-02, -1.3528e-02, -1.5324e-02,  ..., -2.0712e-02,\n",
       "            -2.2508e-02, -2.4304e-02],\n",
       "           [-1.1475e-02, -1.2869e-02, -1.4263e-02,  ..., -1.8445e-02,\n",
       "            -1.9839e-02, -2.1233e-02],\n",
       "           [-1.1219e-02, -1.2211e-02, -1.3203e-02,  ..., -1.6179e-02,\n",
       "            -1.7171e-02, -1.8163e-02],\n",
       "           ...,\n",
       "           [-1.0451e-02, -1.0236e-02, -1.0022e-02,  ..., -9.3804e-03,\n",
       "            -9.1664e-03, -8.9523e-03],\n",
       "           [-1.0194e-02, -9.5783e-03, -8.9622e-03,  ..., -7.1141e-03,\n",
       "            -6.4981e-03, -5.8821e-03],\n",
       "           [-9.9381e-03, -8.9200e-03, -7.9020e-03,  ..., -4.8479e-03,\n",
       "            -3.8298e-03, -2.8118e-03]],\n",
       " \n",
       "          [[ 2.2952e-02,  2.3656e-02,  2.4360e-02,  ...,  2.6471e-02,\n",
       "             2.7175e-02,  2.7879e-02],\n",
       "           [ 2.8662e-02,  2.9014e-02,  2.9365e-02,  ...,  3.0420e-02,\n",
       "             3.0772e-02,  3.1124e-02],\n",
       "           [ 3.4372e-02,  3.4371e-02,  3.4371e-02,  ...,  3.4370e-02,\n",
       "             3.4369e-02,  3.4369e-02],\n",
       "           ...,\n",
       "           [ 5.1500e-02,  5.0444e-02,  4.9387e-02,  ...,  4.6217e-02,\n",
       "             4.5161e-02,  4.4104e-02],\n",
       "           [ 5.7210e-02,  5.5801e-02,  5.4393e-02,  ...,  5.0167e-02,\n",
       "             4.8758e-02,  4.7349e-02],\n",
       "           [ 6.2920e-02,  6.1159e-02,  5.9398e-02,  ...,  5.4116e-02,\n",
       "             5.2355e-02,  5.0594e-02]]],\n",
       " \n",
       " \n",
       "         [[[-2.4907e-02, -2.0400e-02, -1.5893e-02,  ..., -2.3716e-03,\n",
       "             2.1355e-03,  6.6425e-03],\n",
       "           [-2.1948e-02, -1.8474e-02, -1.5000e-02,  ..., -4.5785e-03,\n",
       "            -1.1045e-03,  2.3695e-03],\n",
       "           [-1.8990e-02, -1.6549e-02, -1.4108e-02,  ..., -6.7854e-03,\n",
       "            -4.3445e-03, -1.9036e-03],\n",
       "           ...,\n",
       "           [-1.0114e-02, -1.0773e-02, -1.1431e-02,  ..., -1.3406e-02,\n",
       "            -1.4065e-02, -1.4723e-02],\n",
       "           [-7.1559e-03, -8.8473e-03, -1.0539e-02,  ..., -1.5613e-02,\n",
       "            -1.7305e-02, -1.8996e-02],\n",
       "           [-4.1974e-03, -6.9219e-03, -9.6464e-03,  ..., -1.7820e-02,\n",
       "            -2.0545e-02, -2.3269e-02]],\n",
       " \n",
       "          [[ 2.0324e-02,  2.2039e-02,  2.3754e-02,  ...,  2.8899e-02,\n",
       "             3.0614e-02,  3.2329e-02],\n",
       "           [ 2.0796e-02,  2.2114e-02,  2.3433e-02,  ...,  2.7389e-02,\n",
       "             2.8707e-02,  3.0026e-02],\n",
       "           [ 2.1268e-02,  2.2190e-02,  2.3112e-02,  ...,  2.5878e-02,\n",
       "             2.6800e-02,  2.7722e-02],\n",
       "           ...,\n",
       "           [ 2.2685e-02,  2.2417e-02,  2.2150e-02,  ...,  2.1347e-02,\n",
       "             2.1080e-02,  2.0812e-02],\n",
       "           [ 2.3157e-02,  2.2493e-02,  2.1829e-02,  ...,  1.9837e-02,\n",
       "             1.9173e-02,  1.8509e-02],\n",
       "           [ 2.3629e-02,  2.2569e-02,  2.1508e-02,  ...,  1.8326e-02,\n",
       "             1.7266e-02,  1.6205e-02]],\n",
       " \n",
       "          [[-2.7379e-03, -7.2343e-05,  2.5933e-03,  ...,  1.0590e-02,\n",
       "             1.3256e-02,  1.5921e-02],\n",
       "           [-6.6587e-03, -3.8845e-03, -1.1104e-03,  ...,  7.2120e-03,\n",
       "             9.9861e-03,  1.2760e-02],\n",
       "           [-1.0579e-02, -7.6968e-03, -4.8141e-03,  ...,  3.8339e-03,\n",
       "             6.7166e-03,  9.5992e-03],\n",
       "           ...,\n",
       "           [-2.2342e-02, -1.9133e-02, -1.5925e-02,  ..., -6.3004e-03,\n",
       "            -3.0921e-03,  1.1615e-04],\n",
       "           [-2.6262e-02, -2.2946e-02, -1.9629e-02,  ..., -9.6784e-03,\n",
       "            -6.3617e-03, -3.0449e-03],\n",
       "           [-3.0183e-02, -2.6758e-02, -2.3332e-02,  ..., -1.3057e-02,\n",
       "            -9.6312e-03, -6.2059e-03]],\n",
       " \n",
       "          [[ 2.0824e-04,  2.9404e-03,  5.6727e-03,  ...,  1.3869e-02,\n",
       "             1.6601e-02,  1.9334e-02],\n",
       "           [ 5.5107e-03,  8.2513e-03,  1.0992e-02,  ...,  1.9214e-02,\n",
       "             2.1955e-02,  2.4695e-02],\n",
       "           [ 1.0813e-02,  1.3562e-02,  1.6311e-02,  ...,  2.4559e-02,\n",
       "             2.7308e-02,  3.0057e-02],\n",
       "           ...,\n",
       "           [ 2.6721e-02,  2.9495e-02,  3.2269e-02,  ...,  4.0592e-02,\n",
       "             4.3367e-02,  4.6141e-02],\n",
       "           [ 3.2023e-02,  3.4806e-02,  3.7589e-02,  ...,  4.5937e-02,\n",
       "             4.8720e-02,  5.1503e-02],\n",
       "           [ 3.7325e-02,  4.0117e-02,  4.2908e-02,  ...,  5.1282e-02,\n",
       "             5.4073e-02,  5.6864e-02]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-9.4146e-04,  2.8448e-03,  6.6311e-03,  ...,  1.7990e-02,\n",
       "             2.1776e-02,  2.5563e-02],\n",
       "           [-2.6609e-04,  2.3439e-03,  4.9539e-03,  ...,  1.2784e-02,\n",
       "             1.5394e-02,  1.8004e-02],\n",
       "           [ 4.0927e-04,  1.8430e-03,  3.2767e-03,  ...,  7.5778e-03,\n",
       "             9.0115e-03,  1.0445e-02],\n",
       "           ...,\n",
       "           [ 2.4354e-03,  3.4020e-04, -1.7550e-03,  ..., -8.0404e-03,\n",
       "            -1.0136e-02, -1.2231e-02],\n",
       "           [ 3.1107e-03, -1.6073e-04, -3.4322e-03,  ..., -1.3247e-02,\n",
       "            -1.6518e-02, -1.9789e-02],\n",
       "           [ 3.7861e-03, -6.6166e-04, -5.1094e-03,  ..., -1.8453e-02,\n",
       "            -2.2900e-02, -2.7348e-02]],\n",
       " \n",
       "          [[ 3.7513e-02,  3.9904e-02,  4.2295e-02,  ...,  4.9467e-02,\n",
       "             5.1858e-02,  5.4249e-02],\n",
       "           [ 3.5788e-02,  3.7654e-02,  3.9519e-02,  ...,  4.5116e-02,\n",
       "             4.6981e-02,  4.8847e-02],\n",
       "           [ 3.4063e-02,  3.5403e-02,  3.6744e-02,  ...,  4.0764e-02,\n",
       "             4.2105e-02,  4.3445e-02],\n",
       "           ...,\n",
       "           [ 2.8888e-02,  2.8652e-02,  2.8417e-02,  ...,  2.7710e-02,\n",
       "             2.7475e-02,  2.7239e-02],\n",
       "           [ 2.7163e-02,  2.6402e-02,  2.5641e-02,  ...,  2.3359e-02,\n",
       "             2.2598e-02,  2.1837e-02],\n",
       "           [ 2.5438e-02,  2.4152e-02,  2.2866e-02,  ...,  1.9007e-02,\n",
       "             1.7721e-02,  1.6435e-02]],\n",
       " \n",
       "          [[-2.9859e-02, -2.6372e-02, -2.2885e-02,  ..., -1.2425e-02,\n",
       "            -8.9377e-03, -5.4507e-03],\n",
       "           [-3.0172e-02, -2.6916e-02, -2.3660e-02,  ..., -1.3893e-02,\n",
       "            -1.0638e-02, -7.3820e-03],\n",
       "           [-3.0484e-02, -2.7460e-02, -2.4435e-02,  ..., -1.5362e-02,\n",
       "            -1.2338e-02, -9.3133e-03],\n",
       "           ...,\n",
       "           [-3.1422e-02, -2.9091e-02, -2.6760e-02,  ..., -1.9768e-02,\n",
       "            -1.7438e-02, -1.5107e-02],\n",
       "           [-3.1734e-02, -2.9635e-02, -2.7535e-02,  ..., -2.1237e-02,\n",
       "            -1.9138e-02, -1.7039e-02],\n",
       "           [-3.2046e-02, -3.0178e-02, -2.8310e-02,  ..., -2.2706e-02,\n",
       "            -2.0838e-02, -1.8970e-02]],\n",
       " \n",
       "          [[-5.9187e-03, -1.8086e-03,  2.3015e-03,  ...,  1.4632e-02,\n",
       "             1.8742e-02,  2.2852e-02],\n",
       "           [ 1.7352e-03,  5.0497e-03,  8.3642e-03,  ...,  1.8308e-02,\n",
       "             2.1622e-02,  2.4937e-02],\n",
       "           [ 9.3891e-03,  1.1908e-02,  1.4427e-02,  ...,  2.1983e-02,\n",
       "             2.4502e-02,  2.7021e-02],\n",
       "           ...,\n",
       "           [ 3.2351e-02,  3.2483e-02,  3.2615e-02,  ...,  3.3011e-02,\n",
       "             3.3143e-02,  3.3275e-02],\n",
       "           [ 4.0005e-02,  3.9341e-02,  3.8678e-02,  ...,  3.6687e-02,\n",
       "             3.6023e-02,  3.5360e-02],\n",
       "           [ 4.7659e-02,  4.6200e-02,  4.4740e-02,  ...,  4.0363e-02,\n",
       "             3.8903e-02,  3.7444e-02]]],\n",
       " \n",
       " \n",
       "         [[[-8.5827e-03, -7.7593e-03, -6.9359e-03,  ..., -4.4657e-03,\n",
       "            -3.6423e-03, -2.8189e-03],\n",
       "           [-3.2647e-03, -2.8602e-03, -2.4556e-03,  ..., -1.2421e-03,\n",
       "            -8.3752e-04, -4.3300e-04],\n",
       "           [ 2.0534e-03,  2.0390e-03,  2.0247e-03,  ...,  1.9816e-03,\n",
       "             1.9672e-03,  1.9529e-03],\n",
       "           ...,\n",
       "           [ 1.8008e-02,  1.6737e-02,  1.5466e-02,  ...,  1.1653e-02,\n",
       "             1.0382e-02,  9.1106e-03],\n",
       "           [ 2.3326e-02,  2.1636e-02,  1.9946e-02,  ...,  1.4876e-02,\n",
       "             1.3186e-02,  1.1496e-02],\n",
       "           [ 2.8644e-02,  2.6535e-02,  2.4426e-02,  ...,  1.8100e-02,\n",
       "             1.5991e-02,  1.3882e-02]],\n",
       " \n",
       "          [[ 5.6552e-02,  5.5207e-02,  5.3861e-02,  ...,  4.9823e-02,\n",
       "             4.8478e-02,  4.7132e-02],\n",
       "           [ 4.8124e-02,  4.7104e-02,  4.6084e-02,  ...,  4.3024e-02,\n",
       "             4.2004e-02,  4.0984e-02],\n",
       "           [ 3.9696e-02,  3.9002e-02,  3.8307e-02,  ...,  3.6224e-02,\n",
       "             3.5530e-02,  3.4836e-02],\n",
       "           ...,\n",
       "           [ 1.4411e-02,  1.4694e-02,  1.4977e-02,  ...,  1.5826e-02,\n",
       "             1.6108e-02,  1.6391e-02],\n",
       "           [ 5.9832e-03,  6.5918e-03,  7.2004e-03,  ...,  9.0261e-03,\n",
       "             9.6347e-03,  1.0243e-02],\n",
       "           [-2.4449e-03, -1.5106e-03, -5.7634e-04,  ...,  2.2266e-03,\n",
       "             3.1609e-03,  4.0952e-03]],\n",
       " \n",
       "          [[-3.2733e-02, -3.1252e-02, -2.9770e-02,  ..., -2.5327e-02,\n",
       "            -2.3846e-02, -2.2365e-02],\n",
       "           [-2.5640e-02, -2.4816e-02, -2.3992e-02,  ..., -2.1520e-02,\n",
       "            -2.0696e-02, -1.9872e-02],\n",
       "           [-1.8547e-02, -1.8380e-02, -1.8213e-02,  ..., -1.7713e-02,\n",
       "            -1.7546e-02, -1.7379e-02],\n",
       "           ...,\n",
       "           [ 2.7313e-03,  9.2679e-04, -8.7777e-04,  ..., -6.2914e-03,\n",
       "            -8.0960e-03, -9.9006e-03],\n",
       "           [ 9.8241e-03,  7.3625e-03,  4.9008e-03,  ..., -2.4843e-03,\n",
       "            -4.9460e-03, -7.4077e-03],\n",
       "           [ 1.6917e-02,  1.3798e-02,  1.0679e-02,  ...,  1.3229e-03,\n",
       "            -1.7960e-03, -4.9148e-03]],\n",
       " \n",
       "          [[ 1.0983e-02,  1.7026e-02,  2.3069e-02,  ...,  4.1197e-02,\n",
       "             4.7239e-02,  5.3282e-02],\n",
       "           [ 1.7503e-02,  2.2390e-02,  2.7277e-02,  ...,  4.1938e-02,\n",
       "             4.6826e-02,  5.1713e-02],\n",
       "           [ 2.4022e-02,  2.7754e-02,  3.1485e-02,  ...,  4.2680e-02,\n",
       "             4.6412e-02,  5.0143e-02],\n",
       "           ...,\n",
       "           [ 4.3581e-02,  4.3846e-02,  4.4110e-02,  ...,  4.4905e-02,\n",
       "             4.5170e-02,  4.5435e-02],\n",
       "           [ 5.0100e-02,  4.9210e-02,  4.8319e-02,  ...,  4.5647e-02,\n",
       "             4.4756e-02,  4.3865e-02],\n",
       "           [ 5.6620e-02,  5.4574e-02,  5.2527e-02,  ...,  4.6388e-02,\n",
       "             4.4342e-02,  4.2296e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 9.7512e-03,  1.0562e-02,  1.1373e-02,  ...,  1.3805e-02,\n",
       "             1.4615e-02,  1.5426e-02],\n",
       "           [ 1.1367e-02,  1.2175e-02,  1.2984e-02,  ...,  1.5409e-02,\n",
       "             1.6218e-02,  1.7026e-02],\n",
       "           [ 1.2982e-02,  1.3789e-02,  1.4595e-02,  ...,  1.7014e-02,\n",
       "             1.7820e-02,  1.8627e-02],\n",
       "           ...,\n",
       "           [ 1.7829e-02,  1.8629e-02,  1.9429e-02,  ...,  2.1828e-02,\n",
       "             2.2628e-02,  2.3428e-02],\n",
       "           [ 1.9445e-02,  2.0242e-02,  2.1040e-02,  ...,  2.3433e-02,\n",
       "             2.4231e-02,  2.5028e-02],\n",
       "           [ 2.1060e-02,  2.1856e-02,  2.2651e-02,  ...,  2.5038e-02,\n",
       "             2.5833e-02,  2.6629e-02]],\n",
       " \n",
       "          [[ 6.7526e-02,  6.4886e-02,  6.2245e-02,  ...,  5.4323e-02,\n",
       "             5.1682e-02,  4.9041e-02],\n",
       "           [ 5.5218e-02,  5.3372e-02,  5.1525e-02,  ...,  4.5985e-02,\n",
       "             4.4138e-02,  4.2292e-02],\n",
       "           [ 4.2910e-02,  4.1858e-02,  4.0805e-02,  ...,  3.7647e-02,\n",
       "             3.6594e-02,  3.5542e-02],\n",
       "           ...,\n",
       "           [ 5.9860e-03,  7.3155e-03,  8.6450e-03,  ...,  1.2633e-02,\n",
       "             1.3963e-02,  1.5292e-02],\n",
       "           [-6.3221e-03, -4.1986e-03, -2.0750e-03,  ...,  4.2956e-03,\n",
       "             6.4191e-03,  8.5427e-03],\n",
       "           [-1.8630e-02, -1.5713e-02, -1.2795e-02,  ..., -4.0423e-03,\n",
       "            -1.1247e-03,  1.7929e-03]],\n",
       " \n",
       "          [[ 1.2187e-02,  7.5323e-03,  2.8780e-03,  ..., -1.1085e-02,\n",
       "            -1.5739e-02, -2.0394e-02],\n",
       "           [ 1.5412e-02,  1.0700e-02,  5.9871e-03,  ..., -8.1505e-03,\n",
       "            -1.2863e-02, -1.7576e-02],\n",
       "           [ 1.8638e-02,  1.3867e-02,  9.0962e-03,  ..., -5.2160e-03,\n",
       "            -9.9867e-03, -1.4757e-02],\n",
       "           ...,\n",
       "           [ 2.8314e-02,  2.3369e-02,  1.8424e-02,  ...,  3.5875e-03,\n",
       "            -1.3579e-03, -6.3033e-03],\n",
       "           [ 3.1540e-02,  2.6536e-02,  2.1533e-02,  ...,  6.5220e-03,\n",
       "             1.5184e-03, -3.4852e-03],\n",
       "           [ 3.4766e-02,  2.9704e-02,  2.4642e-02,  ...,  9.4564e-03,\n",
       "             4.3946e-03, -6.6717e-04]],\n",
       " \n",
       "          [[-4.2367e-03,  3.3142e-03,  1.0865e-02,  ...,  3.3518e-02,\n",
       "             4.1069e-02,  4.8619e-02],\n",
       "           [-1.0191e-03,  5.6784e-03,  1.2376e-02,  ...,  3.2468e-02,\n",
       "             3.9166e-02,  4.5863e-02],\n",
       "           [ 2.1986e-03,  8.0426e-03,  1.3887e-02,  ...,  3.1419e-02,\n",
       "             3.7263e-02,  4.3107e-02],\n",
       "           ...,\n",
       "           [ 1.1851e-02,  1.5135e-02,  1.8419e-02,  ...,  2.8271e-02,\n",
       "             3.1555e-02,  3.4838e-02],\n",
       "           [ 1.5069e-02,  1.7500e-02,  1.9930e-02,  ...,  2.7221e-02,\n",
       "             2.9652e-02,  3.2082e-02],\n",
       "           [ 1.8287e-02,  1.9864e-02,  2.1441e-02,  ...,  2.6172e-02,\n",
       "             2.7749e-02,  2.9326e-02]]]], grad_fn=<UpsampleBilinear2DBackward1>),\n",
       " tensor([[[[0.0000]],\n",
       " \n",
       "          [[2.3390]],\n",
       " \n",
       "          [[0.0000]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.0000]],\n",
       " \n",
       "          [[0.3103]],\n",
       " \n",
       "          [[0.5934]]],\n",
       " \n",
       " \n",
       "         [[[0.6525]],\n",
       " \n",
       "          [[0.0000]],\n",
       " \n",
       "          [[1.0103]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.0000]],\n",
       " \n",
       "          [[0.0000]],\n",
       " \n",
       "          [[0.0000]]],\n",
       " \n",
       " \n",
       "         [[[0.0000]],\n",
       " \n",
       "          [[0.1741]],\n",
       " \n",
       "          [[0.0000]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.0000]],\n",
       " \n",
       "          [[0.0000]],\n",
       " \n",
       "          [[0.0000]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[0.2760]],\n",
       " \n",
       "          [[0.5028]],\n",
       " \n",
       "          [[0.0000]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.6824]],\n",
       " \n",
       "          [[0.0000]],\n",
       " \n",
       "          [[0.2280]]],\n",
       " \n",
       " \n",
       "         [[[0.0000]],\n",
       " \n",
       "          [[0.0229]],\n",
       " \n",
       "          [[0.1202]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.0000]],\n",
       " \n",
       "          [[0.0675]],\n",
       " \n",
       "          [[0.0812]]],\n",
       " \n",
       " \n",
       "         [[[0.1903]],\n",
       " \n",
       "          [[0.3471]],\n",
       " \n",
       "          [[0.0000]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.6637]],\n",
       " \n",
       "          [[0.0000]],\n",
       " \n",
       "          [[0.0000]]]], grad_fn=<ReluBackward1>))"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}